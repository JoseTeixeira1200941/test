import json

def remove_duplicates(input_file, output_file):
    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:
        seen = set()
        for line in infile:
            # Load each line as a JSON object
            obj = json.loads(line)

            # Convert the object to a frozenset and check if it's already seen
            obj_set = frozenset(obj.items())
            if obj_set not in seen:
                seen.add(obj_set)
                # Write the unique object to the output file
                json.dump(obj, outfile)
                outfile.write('\n')

if __name__ == "__main__":
    input_file = 'input.json'
    output_file = 'deduplicated_input.json'
    remove_duplicates(input_file, output_file)
